{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectomeDataset(Dataset):\n",
    "    def __init__(self, h5_file, transform=None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # üìå D√©finition des 3 matrices utilis√©es comme canaux\n",
    "        keys = ['FC_correlation', 'SC_gFA', 'SC_density']\n",
    "\n",
    "        with h5py.File(h5_file, 'r') as f:\n",
    "            # üìå On charge les matrices pour CHAQUE patient, en empilant les 3 matrices en (68,68,3)\n",
    "            num_patients = f[keys[0]]['ctrl'].shape[0]  # 27 patients dans chaque groupe\n",
    "\n",
    "            for i in range(num_patients):  # Parcourir les patients\n",
    "                # üìå R√©cup√©rer les matrices SC/FC pour un patient (CTRL)\n",
    "                ctrl_matrices = np.stack([f[key]['ctrl'][i] for key in keys], axis=-1)  # (68, 68, 3)\n",
    "                schz_matrices = np.stack([f[key]['schz'][i] for key in keys], axis=-1)  # (68, 68, 3)\n",
    "\n",
    "                # üìå Ajouter dans les listes\n",
    "                self.data.append(ctrl_matrices)\n",
    "                self.labels.append(0)  # 0 = CTRL\n",
    "                \n",
    "                self.data.append(schz_matrices)\n",
    "                self.labels.append(1)  # 1 = SCHZ\n",
    "\n",
    "        # üìå Convertir en numpy array pour √©viter les erreurs de format\n",
    "        self.data = np.array(self.data, dtype=np.float32)  # Convertir en float32 proprement\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)  # Format compatible avec PyTorch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]  # (68, 68, 3)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # üìå Normalisation individuelle pour chaque canal\n",
    "        for i in range(3):  \n",
    "            img[:, :, i] = (img[:, :, i] - img[:, :, i].min()) / (img[:, :, i].max() - img[:, :, i].min() + 1e-8)\n",
    "\n",
    "        # üìå Convertir en `uint8` (0-255)\n",
    "        img = np.uint8(img * 255)\n",
    "\n",
    "        # üìå Convertir en image PIL (format RGB)\n",
    "        img = Image.fromarray(img, mode=\"RGB\")\n",
    "\n",
    "        # üìå Appliquer les transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©partition des classes dans Train : Counter({np.int64(0): 18, np.int64(1): 18})\n",
      "R√©partition des classes dans Validation : Counter({np.int64(0): 9, np.int64(1): 9})\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2Ô∏è‚É£ Pr√©paration des donn√©es et DataLoader\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# üìå Transformation des images (adapt√© √† DenseNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adapter √† DenseNet\n",
    "    transforms.ToTensor(),  # Convertir en Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# üìå Chargement du dataset\n",
    "h5_path = \"Data_ML/SC_FC_dataset_filtered_68x68.h5\"\n",
    "dataset = ConnectomeDataset(h5_path, transform=transform)\n",
    "\n",
    "# üìå S√©parer les indices des patients CTRL et SCHZ\n",
    "ctrl_indices = [i for i, label in enumerate(dataset.labels) if label == 0]  # CTRL\n",
    "schz_indices = [i for i, label in enumerate(dataset.labels) if label == 1]  # SCHZ\n",
    "\n",
    "# üìå Utiliser directement les labels pour stratifier, pas les indices.\n",
    "ctrl_train, ctrl_val = train_test_split(\n",
    "    ctrl_indices, test_size=0.3, random_state=42, stratify=[dataset.labels[i] for i in ctrl_indices]\n",
    ")\n",
    "\n",
    "schz_train, schz_val = train_test_split(\n",
    "    schz_indices, test_size=0.3, random_state=42, stratify=[dataset.labels[i] for i in schz_indices]\n",
    ")\n",
    "\n",
    "# üìå Fusion des indices pour former les datasets finaux\n",
    "train_indices = ctrl_train + schz_train  # 70% du dataset\n",
    "val_indices = ctrl_val + schz_val        # 30% du dataset\n",
    "\n",
    "# üìå Cr√©ation des datasets √©quilibr√©s\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# üìå V√©rification de la r√©partition des classes\n",
    "train_labels = [dataset.labels[i] for i in train_indices]\n",
    "val_labels = [dataset.labels[i] for i in val_indices]\n",
    "\n",
    "print(\"R√©partition des classes dans Train :\", Counter(train_labels))\n",
    "print(\"R√©partition des classes dans Validation :\", Counter(val_labels))\n",
    "\n",
    "# üìå Cr√©ation des DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Couches entra√Æn√©es :\n",
      "‚úÖ conv1.weight\n",
      "‚úÖ fc.0.weight\n",
      "‚úÖ fc.0.bias\n",
      "‚úÖ fc.2.weight\n",
      "‚úÖ fc.2.bias\n",
      "‚úÖ fc.4.weight\n",
      "‚úÖ fc.4.bias\n",
      "‚úÖ ResNet18 charg√© et adapt√© aux connectomes.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3Ô∏è‚É£ D√©finition du mod√®le ResNet18\n",
    "# ----------------------------\n",
    "\n",
    "# üìå Charger ResNet18 pr√©-entra√Æn√© avec les poids ImageNet\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "# üìå Modifier la premi√®re couche pour accepter 3 canaux (FC_correlation, SC_ADC, SC_density)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=0, bias=False)\n",
    "\n",
    "# üìå D√©bloquer `conv1` pour qu'elle puisse s'entra√Æner\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# üìå Modifier la derni√®re couche pour la classification binaire\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 64),  # R√©duction √† 64 neurones\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),  # Normalisation pour stabiliser l'entra√Ænement\n",
    "    nn.Dropout(0.5),  # R√©duction du sur-apprentissage\n",
    "    nn.Linear(64, 2)  # Classification binaire (CTRL vs SCHZ)\n",
    ")\n",
    "\n",
    "# üìå D√©bloquer `fc` pour qu'il puisse s'entra√Æner\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# üìå Geler toutes les autres couches pour ne pas r√©entra√Æner tout le mod√®le\n",
    "for name, param in model.named_parameters():\n",
    "    if not (name.startswith(\"conv1\") or name.startswith(\"fc\")):\n",
    "        param.requires_grad = False  # On met √† jour uniquement `conv1` et `fc`\n",
    "\n",
    "# üìå D√©placer le mod√®le sur GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# üìå V√©rification : Afficher les couches entra√Ænables\n",
    "print(\"üîπ Couches entra√Æn√©es :\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"‚úÖ {name}\")\n",
    "\n",
    "print(\"‚úÖ ResNet18 charg√© et adapt√© aux connectomes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Epoch 1/100 - Train Loss: 0.6837 - Val Loss: 0.7134\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.7134\n",
      "üìå Epoch 2/100 - Train Loss: 0.6961 - Val Loss: 0.6958\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6958\n",
      "üìå Epoch 3/100 - Train Loss: 0.7906 - Val Loss: 0.6847\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6847\n",
      "üìå Epoch 4/100 - Train Loss: 0.7603 - Val Loss: 0.6415\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6415\n",
      "üìå Epoch 5/100 - Train Loss: 0.6937 - Val Loss: 0.6490\n",
      "‚è≥ Pas d'am√©lioration... (1/20)\n",
      "üìå Epoch 6/100 - Train Loss: 0.5813 - Val Loss: 0.6835\n",
      "‚è≥ Pas d'am√©lioration... (2/20)\n",
      "üìå Epoch 7/100 - Train Loss: 0.6314 - Val Loss: 0.7064\n",
      "‚è≥ Pas d'am√©lioration... (3/20)\n",
      "üìå Epoch 8/100 - Train Loss: 0.5730 - Val Loss: 0.6521\n",
      "‚è≥ Pas d'am√©lioration... (4/20)\n",
      "üìå Epoch 9/100 - Train Loss: 0.5463 - Val Loss: 0.6901\n",
      "‚è≥ Pas d'am√©lioration... (5/20)\n",
      "üìå Epoch 10/100 - Train Loss: 0.6210 - Val Loss: 0.7307\n",
      "‚è≥ Pas d'am√©lioration... (6/20)\n",
      "üìå Epoch 11/100 - Train Loss: 0.7192 - Val Loss: 0.6996\n",
      "‚è≥ Pas d'am√©lioration... (7/20)\n",
      "üìå Epoch 12/100 - Train Loss: 0.6561 - Val Loss: 0.6961\n",
      "‚è≥ Pas d'am√©lioration... (8/20)\n",
      "üìå Epoch 13/100 - Train Loss: 0.4717 - Val Loss: 0.6789\n",
      "‚è≥ Pas d'am√©lioration... (9/20)\n",
      "üìå Epoch 14/100 - Train Loss: 0.6190 - Val Loss: 0.6692\n",
      "‚è≥ Pas d'am√©lioration... (10/20)\n",
      "üìå Epoch 15/100 - Train Loss: 0.4947 - Val Loss: 0.6563\n",
      "‚è≥ Pas d'am√©lioration... (11/20)\n",
      "üìå Epoch 16/100 - Train Loss: 0.4753 - Val Loss: 0.6652\n",
      "‚è≥ Pas d'am√©lioration... (12/20)\n",
      "üìå Epoch 17/100 - Train Loss: 0.5230 - Val Loss: 0.6679\n",
      "‚è≥ Pas d'am√©lioration... (13/20)\n",
      "üìå Epoch 18/100 - Train Loss: 0.5036 - Val Loss: 0.6865\n",
      "‚è≥ Pas d'am√©lioration... (14/20)\n",
      "üìå Epoch 19/100 - Train Loss: 0.5182 - Val Loss: 0.6604\n",
      "‚è≥ Pas d'am√©lioration... (15/20)\n",
      "üìå Epoch 20/100 - Train Loss: 0.4433 - Val Loss: 0.6483\n",
      "‚è≥ Pas d'am√©lioration... (16/20)\n",
      "üìå Epoch 21/100 - Train Loss: 0.5424 - Val Loss: 0.6465\n",
      "‚è≥ Pas d'am√©lioration... (17/20)\n",
      "üìå Epoch 22/100 - Train Loss: 0.4922 - Val Loss: 0.6389\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6389\n",
      "üìå Epoch 23/100 - Train Loss: 0.4289 - Val Loss: 0.6459\n",
      "‚è≥ Pas d'am√©lioration... (1/20)\n",
      "üìå Epoch 24/100 - Train Loss: 0.5040 - Val Loss: 0.6224\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6224\n",
      "üìå Epoch 25/100 - Train Loss: 0.3475 - Val Loss: 0.6230\n",
      "‚è≥ Pas d'am√©lioration... (1/20)\n",
      "üìå Epoch 26/100 - Train Loss: 0.4403 - Val Loss: 0.6281\n",
      "‚è≥ Pas d'am√©lioration... (2/20)\n",
      "üìå Epoch 27/100 - Train Loss: 0.5274 - Val Loss: 0.6481\n",
      "‚è≥ Pas d'am√©lioration... (3/20)\n",
      "üìå Epoch 28/100 - Train Loss: 0.5297 - Val Loss: 0.6312\n",
      "‚è≥ Pas d'am√©lioration... (4/20)\n",
      "üìå Epoch 29/100 - Train Loss: 0.4413 - Val Loss: 0.6318\n",
      "‚è≥ Pas d'am√©lioration... (5/20)\n",
      "üìå Epoch 30/100 - Train Loss: 0.3527 - Val Loss: 0.6154\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.6154\n",
      "üìå Epoch 31/100 - Train Loss: 0.3837 - Val Loss: 0.6227\n",
      "‚è≥ Pas d'am√©lioration... (1/20)\n",
      "üìå Epoch 32/100 - Train Loss: 0.4872 - Val Loss: 0.6233\n",
      "‚è≥ Pas d'am√©lioration... (2/20)\n",
      "üìå Epoch 33/100 - Train Loss: 0.4289 - Val Loss: 0.5983\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.5983\n",
      "üìå Epoch 34/100 - Train Loss: 0.3368 - Val Loss: 0.5634\n",
      "‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: 0.5634\n",
      "üìå Epoch 35/100 - Train Loss: 0.3464 - Val Loss: 0.6073\n",
      "‚è≥ Pas d'am√©lioration... (1/20)\n",
      "üìå Epoch 36/100 - Train Loss: 0.3310 - Val Loss: 0.5955\n",
      "‚è≥ Pas d'am√©lioration... (2/20)\n",
      "üìå Epoch 37/100 - Train Loss: 0.3386 - Val Loss: 0.6141\n",
      "‚è≥ Pas d'am√©lioration... (3/20)\n",
      "üìå Epoch 38/100 - Train Loss: 0.3312 - Val Loss: 0.6206\n",
      "‚è≥ Pas d'am√©lioration... (4/20)\n",
      "üìå Epoch 39/100 - Train Loss: 0.4309 - Val Loss: 0.6501\n",
      "‚è≥ Pas d'am√©lioration... (5/20)\n",
      "üìå Epoch 40/100 - Train Loss: 0.3315 - Val Loss: 0.6453\n",
      "‚è≥ Pas d'am√©lioration... (6/20)\n",
      "üìå Epoch 41/100 - Train Loss: 0.2874 - Val Loss: 0.6293\n",
      "‚è≥ Pas d'am√©lioration... (7/20)\n",
      "üìå Epoch 42/100 - Train Loss: 0.3247 - Val Loss: 0.6450\n",
      "‚è≥ Pas d'am√©lioration... (8/20)\n",
      "üìå Epoch 43/100 - Train Loss: 0.3505 - Val Loss: 0.6359\n",
      "‚è≥ Pas d'am√©lioration... (9/20)\n",
      "üìå Epoch 44/100 - Train Loss: 0.2919 - Val Loss: 0.6243\n",
      "‚è≥ Pas d'am√©lioration... (10/20)\n",
      "üìå Epoch 45/100 - Train Loss: 0.3059 - Val Loss: 0.6476\n",
      "‚è≥ Pas d'am√©lioration... (11/20)\n",
      "üìå Epoch 46/100 - Train Loss: 0.2994 - Val Loss: 0.6618\n",
      "‚è≥ Pas d'am√©lioration... (12/20)\n",
      "üìå Epoch 47/100 - Train Loss: 0.2845 - Val Loss: 0.6976\n",
      "‚è≥ Pas d'am√©lioration... (13/20)\n",
      "üìå Epoch 48/100 - Train Loss: 0.3241 - Val Loss: 0.6893\n",
      "‚è≥ Pas d'am√©lioration... (14/20)\n",
      "üìå Epoch 49/100 - Train Loss: 0.4276 - Val Loss: 0.6649\n",
      "‚è≥ Pas d'am√©lioration... (15/20)\n",
      "üìå Epoch 50/100 - Train Loss: 0.3753 - Val Loss: 0.6355\n",
      "‚è≥ Pas d'am√©lioration... (16/20)\n",
      "üìå Epoch 51/100 - Train Loss: 0.2859 - Val Loss: 0.6363\n",
      "‚è≥ Pas d'am√©lioration... (17/20)\n",
      "üìå Epoch 52/100 - Train Loss: 0.2749 - Val Loss: 0.6277\n",
      "‚è≥ Pas d'am√©lioration... (18/20)\n",
      "üìå Epoch 53/100 - Train Loss: 0.3145 - Val Loss: 0.6184\n",
      "‚è≥ Pas d'am√©lioration... (19/20)\n",
      "üìå Epoch 54/100 - Train Loss: 0.2673 - Val Loss: 0.5978\n",
      "‚è≥ Pas d'am√©lioration... (20/20)\n",
      "üõë Early Stopping activ√© apr√®s 54 epochs. Meilleure Val Loss: 0.5634\n",
      "‚úÖ Entra√Ænement termin√©, mod√®le optimal charg√© !\n"
     ]
    }
   ],
   "source": [
    "# üìå D√©tection automatique du device (GPU ou CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_amp = torch.cuda.is_available()  # Activer Mixed Precision seulement si GPU dispo\n",
    "\n",
    "# üìå D√©finition du mod√®le et des hyperparam√®tres\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.fc.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "\n",
    "# üìå Activer GradScaler uniquement si CUDA est disponible\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 20\n",
    "best_loss = float('inf')  \n",
    "early_stop_counter = 0\n",
    "\n",
    "best_model_path = \"Model/best_resnet18_model_test.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ----- ENTRA√éNEMENT -----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        if len(inputs) == 0:\n",
    "            continue\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\" if use_amp else \"cpu\", enabled=use_amp): \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ----- VALIDATION (ajout√©e ici) -----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # üìå Affichage des losses\n",
    "    print(f\"üìå Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # üìå Early Stopping bas√© sur la Validation Loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"‚úÖ Meilleur mod√®le sauvegard√© avec Val Loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"‚è≥ Pas d'am√©lioration... ({early_stop_counter}/{patience})\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"üõë Early Stopping activ√© apr√®s {epoch+1} epochs. Meilleure Val Loss: {best_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# üìå Charger le meilleur mod√®le apr√®s l'entra√Ænement\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "print(\"‚úÖ Entra√Ænement termin√©, mod√®le optimal charg√© !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CTRL       0.80      0.89      0.84         9\n",
      "        SCHZ       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.84      0.83      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5Ô∏è‚É£ √âvaluation du mod√®le\n",
    "# ----------------------------\n",
    "\n",
    "# üìå Charger le meilleur mod√®le sauvegard√© avec `weights_only=True`\n",
    "best_model_path = \"Model/best_resnet18_model.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device, weights_only=False))  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# üìå √âvaluation du mod√®le\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# üìå Calcul des performances\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# üìå Affichage des r√©sultats\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['CTRL', 'SCHZ']))\n",
    "\n",
    "# üìå Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['CTRL', 'SCHZ'], yticklabels=['CTRL', 'SCHZ'])\n",
    "plt.xlabel(\"Pr√©dictions\")\n",
    "plt.ylabel(\"R√©el\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
