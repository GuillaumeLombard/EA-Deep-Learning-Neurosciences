{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectomeDataset(Dataset):\n",
    "    def __init__(self, h5_file, transform=None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # 📌 Définition des 3 matrices utilisées comme canaux\n",
    "        keys = ['FC_correlation', 'SC_gFA', 'SC_density']\n",
    "\n",
    "        with h5py.File(h5_file, 'r') as f:\n",
    "            # 📌 On charge les matrices pour CHAQUE patient, en empilant les 3 matrices en (68,68,3)\n",
    "            num_patients = f[keys[0]]['ctrl'].shape[0]  # 27 patients dans chaque groupe\n",
    "\n",
    "            for i in range(num_patients):  # Parcourir les patients\n",
    "                # 📌 Récupérer les matrices SC/FC pour un patient (CTRL)\n",
    "                ctrl_matrices = np.stack([f[key]['ctrl'][i] for key in keys], axis=-1)  # (68, 68, 3)\n",
    "                schz_matrices = np.stack([f[key]['schz'][i] for key in keys], axis=-1)  # (68, 68, 3)\n",
    "\n",
    "                # 📌 Ajouter dans les listes\n",
    "                self.data.append(ctrl_matrices)\n",
    "                self.labels.append(0)  # 0 = CTRL\n",
    "                \n",
    "                self.data.append(schz_matrices)\n",
    "                self.labels.append(1)  # 1 = SCHZ\n",
    "\n",
    "        # 📌 Convertir en numpy array pour éviter les erreurs de format\n",
    "        self.data = np.array(self.data, dtype=np.float32)  # Convertir en float32 proprement\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)  # Format compatible avec PyTorch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]  # (68, 68, 3)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 📌 Normalisation individuelle pour chaque canal\n",
    "        for i in range(3):  \n",
    "            img[:, :, i] = (img[:, :, i] - img[:, :, i].min()) / (img[:, :, i].max() - img[:, :, i].min() + 1e-8)\n",
    "\n",
    "        # 📌 Convertir en `uint8` (0-255)\n",
    "        img = np.uint8(img * 255)\n",
    "\n",
    "        # 📌 Convertir en image PIL (format RGB)\n",
    "        img = Image.fromarray(img, mode=\"RGB\")\n",
    "\n",
    "        # 📌 Appliquer les transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des classes dans Train : Counter({np.int64(0): 18, np.int64(1): 18})\n",
      "Répartition des classes dans Validation : Counter({np.int64(0): 9, np.int64(1): 9})\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2️⃣ Préparation des données et DataLoader\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 📌 Transformation des images (adapté à DenseNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adapter à DenseNet\n",
    "    transforms.ToTensor(),  # Convertir en Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 📌 Chargement du dataset\n",
    "h5_path = \"Data_ML/SC_FC_dataset_filtered_68x68.h5\"\n",
    "dataset = ConnectomeDataset(h5_path, transform=transform)\n",
    "\n",
    "# 📌 Séparer les indices des patients CTRL et SCHZ\n",
    "ctrl_indices = [i for i, label in enumerate(dataset.labels) if label == 0]  # CTRL\n",
    "schz_indices = [i for i, label in enumerate(dataset.labels) if label == 1]  # SCHZ\n",
    "\n",
    "# 📌 Utiliser directement les labels pour stratifier, pas les indices.\n",
    "ctrl_train, ctrl_val = train_test_split(\n",
    "    ctrl_indices, test_size=0.3, random_state=42, stratify=[dataset.labels[i] for i in ctrl_indices]\n",
    ")\n",
    "\n",
    "schz_train, schz_val = train_test_split(\n",
    "    schz_indices, test_size=0.3, random_state=42, stratify=[dataset.labels[i] for i in schz_indices]\n",
    ")\n",
    "\n",
    "# 📌 Fusion des indices pour former les datasets finaux\n",
    "train_indices = ctrl_train + schz_train  # 70% du dataset\n",
    "val_indices = ctrl_val + schz_val        # 30% du dataset\n",
    "\n",
    "# 📌 Création des datasets équilibrés\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# 📌 Vérification de la répartition des classes\n",
    "train_labels = [dataset.labels[i] for i in train_indices]\n",
    "val_labels = [dataset.labels[i] for i in val_indices]\n",
    "\n",
    "print(\"Répartition des classes dans Train :\", Counter(train_labels))\n",
    "print(\"Répartition des classes dans Validation :\", Counter(val_labels))\n",
    "\n",
    "# 📌 Création des DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Couches entraînées :\n",
      "✅ conv1.weight\n",
      "✅ fc.0.weight\n",
      "✅ fc.0.bias\n",
      "✅ fc.2.weight\n",
      "✅ fc.2.bias\n",
      "✅ fc.4.weight\n",
      "✅ fc.4.bias\n",
      "✅ ResNet18 chargé et adapté aux connectomes.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3️⃣ Définition du modèle ResNet18\n",
    "# ----------------------------\n",
    "\n",
    "# 📌 Charger ResNet18 pré-entraîné avec les poids ImageNet\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "# 📌 Modifier la première couche pour accepter 3 canaux (FC_correlation, SC_ADC, SC_density)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=0, bias=False)\n",
    "\n",
    "# 📌 Débloquer `conv1` pour qu'elle puisse s'entraîner\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 📌 Modifier la dernière couche pour la classification binaire\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 64),  # Réduction à 64 neurones\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),  # Normalisation pour stabiliser l'entraînement\n",
    "    nn.Dropout(0.5),  # Réduction du sur-apprentissage\n",
    "    nn.Linear(64, 2)  # Classification binaire (CTRL vs SCHZ)\n",
    ")\n",
    "\n",
    "# 📌 Débloquer `fc` pour qu'il puisse s'entraîner\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 📌 Geler toutes les autres couches pour ne pas réentraîner tout le modèle\n",
    "for name, param in model.named_parameters():\n",
    "    if not (name.startswith(\"conv1\") or name.startswith(\"fc\")):\n",
    "        param.requires_grad = False  # On met à jour uniquement `conv1` et `fc`\n",
    "\n",
    "# 📌 Déplacer le modèle sur GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 📌 Vérification : Afficher les couches entraînables\n",
    "print(\"🔹 Couches entraînées :\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"✅ {name}\")\n",
    "\n",
    "print(\"✅ ResNet18 chargé et adapté aux connectomes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Epoch 1/100 - Train Loss: 0.6837 - Val Loss: 0.7134\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.7134\n",
      "📌 Epoch 2/100 - Train Loss: 0.6961 - Val Loss: 0.6958\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6958\n",
      "📌 Epoch 3/100 - Train Loss: 0.7906 - Val Loss: 0.6847\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6847\n",
      "📌 Epoch 4/100 - Train Loss: 0.7603 - Val Loss: 0.6415\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6415\n",
      "📌 Epoch 5/100 - Train Loss: 0.6937 - Val Loss: 0.6490\n",
      "⏳ Pas d'amélioration... (1/20)\n",
      "📌 Epoch 6/100 - Train Loss: 0.5813 - Val Loss: 0.6835\n",
      "⏳ Pas d'amélioration... (2/20)\n",
      "📌 Epoch 7/100 - Train Loss: 0.6314 - Val Loss: 0.7064\n",
      "⏳ Pas d'amélioration... (3/20)\n",
      "📌 Epoch 8/100 - Train Loss: 0.5730 - Val Loss: 0.6521\n",
      "⏳ Pas d'amélioration... (4/20)\n",
      "📌 Epoch 9/100 - Train Loss: 0.5463 - Val Loss: 0.6901\n",
      "⏳ Pas d'amélioration... (5/20)\n",
      "📌 Epoch 10/100 - Train Loss: 0.6210 - Val Loss: 0.7307\n",
      "⏳ Pas d'amélioration... (6/20)\n",
      "📌 Epoch 11/100 - Train Loss: 0.7192 - Val Loss: 0.6996\n",
      "⏳ Pas d'amélioration... (7/20)\n",
      "📌 Epoch 12/100 - Train Loss: 0.6561 - Val Loss: 0.6961\n",
      "⏳ Pas d'amélioration... (8/20)\n",
      "📌 Epoch 13/100 - Train Loss: 0.4717 - Val Loss: 0.6789\n",
      "⏳ Pas d'amélioration... (9/20)\n",
      "📌 Epoch 14/100 - Train Loss: 0.6190 - Val Loss: 0.6692\n",
      "⏳ Pas d'amélioration... (10/20)\n",
      "📌 Epoch 15/100 - Train Loss: 0.4947 - Val Loss: 0.6563\n",
      "⏳ Pas d'amélioration... (11/20)\n",
      "📌 Epoch 16/100 - Train Loss: 0.4753 - Val Loss: 0.6652\n",
      "⏳ Pas d'amélioration... (12/20)\n",
      "📌 Epoch 17/100 - Train Loss: 0.5230 - Val Loss: 0.6679\n",
      "⏳ Pas d'amélioration... (13/20)\n",
      "📌 Epoch 18/100 - Train Loss: 0.5036 - Val Loss: 0.6865\n",
      "⏳ Pas d'amélioration... (14/20)\n",
      "📌 Epoch 19/100 - Train Loss: 0.5182 - Val Loss: 0.6604\n",
      "⏳ Pas d'amélioration... (15/20)\n",
      "📌 Epoch 20/100 - Train Loss: 0.4433 - Val Loss: 0.6483\n",
      "⏳ Pas d'amélioration... (16/20)\n",
      "📌 Epoch 21/100 - Train Loss: 0.5424 - Val Loss: 0.6465\n",
      "⏳ Pas d'amélioration... (17/20)\n",
      "📌 Epoch 22/100 - Train Loss: 0.4922 - Val Loss: 0.6389\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6389\n",
      "📌 Epoch 23/100 - Train Loss: 0.4289 - Val Loss: 0.6459\n",
      "⏳ Pas d'amélioration... (1/20)\n",
      "📌 Epoch 24/100 - Train Loss: 0.5040 - Val Loss: 0.6224\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6224\n",
      "📌 Epoch 25/100 - Train Loss: 0.3475 - Val Loss: 0.6230\n",
      "⏳ Pas d'amélioration... (1/20)\n",
      "📌 Epoch 26/100 - Train Loss: 0.4403 - Val Loss: 0.6281\n",
      "⏳ Pas d'amélioration... (2/20)\n",
      "📌 Epoch 27/100 - Train Loss: 0.5274 - Val Loss: 0.6481\n",
      "⏳ Pas d'amélioration... (3/20)\n",
      "📌 Epoch 28/100 - Train Loss: 0.5297 - Val Loss: 0.6312\n",
      "⏳ Pas d'amélioration... (4/20)\n",
      "📌 Epoch 29/100 - Train Loss: 0.4413 - Val Loss: 0.6318\n",
      "⏳ Pas d'amélioration... (5/20)\n",
      "📌 Epoch 30/100 - Train Loss: 0.3527 - Val Loss: 0.6154\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.6154\n",
      "📌 Epoch 31/100 - Train Loss: 0.3837 - Val Loss: 0.6227\n",
      "⏳ Pas d'amélioration... (1/20)\n",
      "📌 Epoch 32/100 - Train Loss: 0.4872 - Val Loss: 0.6233\n",
      "⏳ Pas d'amélioration... (2/20)\n",
      "📌 Epoch 33/100 - Train Loss: 0.4289 - Val Loss: 0.5983\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.5983\n",
      "📌 Epoch 34/100 - Train Loss: 0.3368 - Val Loss: 0.5634\n",
      "✅ Meilleur modèle sauvegardé avec Val Loss: 0.5634\n",
      "📌 Epoch 35/100 - Train Loss: 0.3464 - Val Loss: 0.6073\n",
      "⏳ Pas d'amélioration... (1/20)\n",
      "📌 Epoch 36/100 - Train Loss: 0.3310 - Val Loss: 0.5955\n",
      "⏳ Pas d'amélioration... (2/20)\n",
      "📌 Epoch 37/100 - Train Loss: 0.3386 - Val Loss: 0.6141\n",
      "⏳ Pas d'amélioration... (3/20)\n",
      "📌 Epoch 38/100 - Train Loss: 0.3312 - Val Loss: 0.6206\n",
      "⏳ Pas d'amélioration... (4/20)\n",
      "📌 Epoch 39/100 - Train Loss: 0.4309 - Val Loss: 0.6501\n",
      "⏳ Pas d'amélioration... (5/20)\n",
      "📌 Epoch 40/100 - Train Loss: 0.3315 - Val Loss: 0.6453\n",
      "⏳ Pas d'amélioration... (6/20)\n",
      "📌 Epoch 41/100 - Train Loss: 0.2874 - Val Loss: 0.6293\n",
      "⏳ Pas d'amélioration... (7/20)\n",
      "📌 Epoch 42/100 - Train Loss: 0.3247 - Val Loss: 0.6450\n",
      "⏳ Pas d'amélioration... (8/20)\n",
      "📌 Epoch 43/100 - Train Loss: 0.3505 - Val Loss: 0.6359\n",
      "⏳ Pas d'amélioration... (9/20)\n",
      "📌 Epoch 44/100 - Train Loss: 0.2919 - Val Loss: 0.6243\n",
      "⏳ Pas d'amélioration... (10/20)\n",
      "📌 Epoch 45/100 - Train Loss: 0.3059 - Val Loss: 0.6476\n",
      "⏳ Pas d'amélioration... (11/20)\n",
      "📌 Epoch 46/100 - Train Loss: 0.2994 - Val Loss: 0.6618\n",
      "⏳ Pas d'amélioration... (12/20)\n",
      "📌 Epoch 47/100 - Train Loss: 0.2845 - Val Loss: 0.6976\n",
      "⏳ Pas d'amélioration... (13/20)\n",
      "📌 Epoch 48/100 - Train Loss: 0.3241 - Val Loss: 0.6893\n",
      "⏳ Pas d'amélioration... (14/20)\n",
      "📌 Epoch 49/100 - Train Loss: 0.4276 - Val Loss: 0.6649\n",
      "⏳ Pas d'amélioration... (15/20)\n",
      "📌 Epoch 50/100 - Train Loss: 0.3753 - Val Loss: 0.6355\n",
      "⏳ Pas d'amélioration... (16/20)\n",
      "📌 Epoch 51/100 - Train Loss: 0.2859 - Val Loss: 0.6363\n",
      "⏳ Pas d'amélioration... (17/20)\n",
      "📌 Epoch 52/100 - Train Loss: 0.2749 - Val Loss: 0.6277\n",
      "⏳ Pas d'amélioration... (18/20)\n",
      "📌 Epoch 53/100 - Train Loss: 0.3145 - Val Loss: 0.6184\n",
      "⏳ Pas d'amélioration... (19/20)\n",
      "📌 Epoch 54/100 - Train Loss: 0.2673 - Val Loss: 0.5978\n",
      "⏳ Pas d'amélioration... (20/20)\n",
      "🛑 Early Stopping activé après 54 epochs. Meilleure Val Loss: 0.5634\n",
      "✅ Entraînement terminé, modèle optimal chargé !\n"
     ]
    }
   ],
   "source": [
    "# 📌 Détection automatique du device (GPU ou CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_amp = torch.cuda.is_available()  # Activer Mixed Precision seulement si GPU dispo\n",
    "\n",
    "# 📌 Définition du modèle et des hyperparamètres\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.fc.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "\n",
    "# 📌 Activer GradScaler uniquement si CUDA est disponible\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 20\n",
    "best_loss = float('inf')  \n",
    "early_stop_counter = 0\n",
    "\n",
    "best_model_path = \"Model/best_resnet18_model_test.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ----- ENTRAÎNEMENT -----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        if len(inputs) == 0:\n",
    "            continue\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\" if use_amp else \"cpu\", enabled=use_amp): \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ----- VALIDATION (ajoutée ici) -----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # 📌 Affichage des losses\n",
    "    print(f\"📌 Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # 📌 Early Stopping basé sur la Validation Loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Meilleur modèle sauvegardé avec Val Loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"⏳ Pas d'amélioration... ({early_stop_counter}/{patience})\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"🛑 Early Stopping activé après {epoch+1} epochs. Meilleure Val Loss: {best_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# 📌 Charger le meilleur modèle après l'entraînement\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "print(\"✅ Entraînement terminé, modèle optimal chargé !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CTRL       0.80      0.89      0.84         9\n",
      "        SCHZ       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.84      0.83      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5️⃣ Évaluation du modèle\n",
    "# ----------------------------\n",
    "\n",
    "# 📌 Charger le meilleur modèle sauvegardé avec `weights_only=True`\n",
    "best_model_path = \"Model/best_resnet18_model.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device, weights_only=False))  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 📌 Évaluation du modèle\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 📌 Calcul des performances\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 📌 Affichage des résultats\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['CTRL', 'SCHZ']))\n",
    "\n",
    "# 📌 Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['CTRL', 'SCHZ'], yticklabels=['CTRL', 'SCHZ'])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
