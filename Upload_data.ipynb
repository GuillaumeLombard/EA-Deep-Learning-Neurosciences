{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a pour but d'extraire les data matrices dont nous avons besoin pour travailler. Il faut commencer par sélectionner la discrétisation voulue. \n",
    "\n",
    "A l'issu, nous avons un nouveau .h5 SC_FC_dataset_filtered_discretisationxdiscretisation.h5 et un csv avec le nom des région corticale. A noter que le filtre ixc est appliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretisation_possible = {83 : 0, 129 : 1, 234 : 2, 463 : 3, 1015 : 4} \n",
    "discretisation_chosen = discretisation_possible[83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data_ML/SC_FC_dataset_filtered_68x68.h5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le masque cortical\n",
    "labels_data = sio.loadmat('Data/labels_index_CORTICAL_Laus2008_all_scales.mat')\n",
    "ixc = labels_data['ixc'][0, discretisation_chosen][0] - 1  # Ajustement d'indexation\n",
    "\n",
    "# Chemin du fichier de données\n",
    "file_path = 'Data/27_SCHZ_CTRL_dataset.mat'\n",
    "output_path = f'Data_ML/SC_FC_dataset_filtered_{len(ixc)}x{len(ixc)}.h5'\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    with h5py.File(output_path, 'w') as hf:\n",
    "        for key in f['SC_FC_Connectomes'].keys():\n",
    "            if key == 'demographics':  # Ignorer demographics\n",
    "                continue\n",
    "            group = f['SC_FC_Connectomes'][key]\n",
    "            hf.create_group(key)\n",
    "            \n",
    "            for sub_key in group.keys():\n",
    "                data = group[sub_key][discretisation_chosen, 0]  # Référence\n",
    "                matrix = f[data][:]  # Charger la matrice\n",
    "                filtered_matrix = matrix[:, ixc, :][:, :, ixc]  # Appliquer le filtre\n",
    "                hf[key].create_dataset(sub_key, data=filtered_matrix)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clés principales : ['FC_correlation', 'SC_ADC', 'SC_density', 'SC_gFA', 'SC_length_of_fibers', 'SC_number_of_fibers']\n",
      "📂 Groupe: FC_correlation\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float32\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float32\n",
      "📂 Groupe: SC_ADC\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float64\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float64\n",
      "📂 Groupe: SC_density\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float64\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float64\n",
      "📂 Groupe: SC_gFA\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float64\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float64\n",
      "📂 Groupe: SC_length_of_fibers\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float64\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float64\n",
      "📂 Groupe: SC_number_of_fibers\n",
      "  🗂️ Dataset: ctrl, shape=(27, 68, 68), dtype=float64\n",
      "  🗂️ Dataset: schz, shape=(27, 68, 68), dtype=float64\n"
     ]
    }
   ],
   "source": [
    "# Ouvrir le fichier HDF5\n",
    "file_path = output_path\n",
    "\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    def explore_group(group, indent=0):\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                print(\"  \" * indent + f\"📂 Groupe: {key}\")\n",
    "                explore_group(item, indent + 1)\n",
    "            else:\n",
    "                print(\"  \" * indent + f\"🗂️ Dataset: {key}, shape={item.shape}, dtype={item.dtype}\")\n",
    "\n",
    "    print(\"Clés principales :\", list(hf.keys()))\n",
    "    explore_group(hf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data_ML/regions_corticales_68_indices.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le fichier de labels\n",
    "labels_file = 'Data/labels_index_CORTICAL_Laus2008_all_scales.mat'\n",
    "labels_data = sio.loadmat(labels_file)\n",
    "\n",
    "# Extraire le masque cortical et la liste des labels\n",
    "llist = labels_data['llist']\n",
    "\n",
    "# Créer une liste des noms des régions corticales\n",
    "region_names = [llist[0, discretisation_chosen][i, 0][0] for i in range(llist[0, discretisation_chosen].shape[0])]\n",
    "\n",
    "# Créer un DataFrame\n",
    "df_regions = pd.DataFrame({'Indice': range(1, len(region_names) + 1), 'Région Cérébrale': region_names})\n",
    "\n",
    "# Enregistrer au format CSV\n",
    "csv_path = f'Data_ML/regions_corticales_{llist[0, discretisation_chosen].shape[0]}_indices.csv'\n",
    "df_regions.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
